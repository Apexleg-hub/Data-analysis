{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a87844",
   "metadata": {},
   "source": [
    "**Logistic Regression**, along with code examples and use cases:\n",
    "\n",
    "---\n",
    "\n",
    "### **What is Logistic Regression?**  \n",
    "**Logistic Regression** is a **classification algorithm** (not regression!) used to predict **binary outcomes** \n",
    "(yes/no, 0/1, spam/not spam). It estimates the probability that an input belongs to a specific class.  \n",
    "\n",
    "**How it works**:  \n",
    "1. It uses the **sigmoid function** to squash predictions into a range between 0 and 1.  \n",
    "2. If the probability is **> 0.5**, the output is class \"1\"; otherwise, class \"0\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f679d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Code Example**  \n",
    "#Letâ€™s predict whether a tumor is **malignant** (1) or **benign** (0) using the Breast Cancer dataset:  \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "data\n",
    "X = data.data  # Features (e.g., tumor radius, texture)\n",
    "y = data.target  # Target (0=benign, 1=malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54152687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Accuracy: 37.72%\n",
      "Confusion Matrix:\n",
      "[[43  0]\n",
      " [71  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda33\\envs\\ml_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train with more iterations and scaled data\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]  # Probabilities of class \"1\"\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a8a72",
   "metadata": {},
   "source": [
    "#---\n",
    "\n",
    "### **When to Use Logistic Regression**  \n",
    "'''- **Binary classification problems**:  \n",
    "  - Medical diagnosis (e.g., diabetes yes/no).  \n",
    "  - Spam detection (spam/not spam).  \n",
    "  - Customer churn prediction (stay/leave).  \n",
    "\n",
    "- **Multi-class classification** (with extensions like one-vs-rest):  \n",
    "  - Handwritten digit recognition (0-9).  \n",
    "  - Iris flower species classification.''' \n",
    "\n",
    "#---\n",
    "\n",
    "### **Key Features**  \n",
    "'''1. **Probabilistic Output**: Returns probabilities (e.g., 80% chance of being spam).  \n",
    "2. **Interpretability**: Coefficients show how features affect the outcome.  \n",
    "3. **Efficiency**: Works well with small-to-medium datasets.''' \n",
    "\n",
    "#---\n",
    "\n",
    "### **Example Datasets**  \n",
    "'''1. **Bank Customer Churn**: Predict if a customer will leave (0) or stay (1) based on account activity.  \n",
    "2. **Email Classification**: Classify emails as spam (1) or not spam (0).  \n",
    "3. **Credit Risk**: Approve (1) or reject (0) a loan application.'''  \n",
    "\n",
    "#---\n",
    "\n",
    "'''### **Logistic Regression vs. Linear Regression**  \n",
    "| **Aspect**          | **Logistic Regression**           | **Linear Regression**          |  \n",
    "|----------------------|-----------------------------------|---------------------------------|  \n",
    "| **Output**           | Probability (0-1)                 | Continuous value (e.g., price)  |  \n",
    "| **Use Case**         | Classification                    | Regression                      |  \n",
    "| **Equation**         | Sigmoid function                  | Straight line                   |  '''\n",
    "\n",
    "#---\n",
    "\n",
    "### **Limitations**  \n",
    "'''- Assumes a **linear decision boundary** between classes.  \n",
    "- Struggles with highly complex/non-linear relationships (use SVM or neural networks instead).  \n",
    "\n",
    "Logistic Regression is a foundational tool for classification tasksâ€”simple, fast, and interpretable! ðŸŽ¯'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
